/*
 * Copyright OpenSearch Contributors
 * SPDX-License-Identifier: Apache-2.0
 */

package com.amazon.dataprepper.plugins.processor.csv;

import com.amazon.dataprepper.metrics.PluginMetrics;
import com.amazon.dataprepper.model.annotations.DataPrepperPlugin;
import com.amazon.dataprepper.model.annotations.DataPrepperPluginConstructor;
import com.amazon.dataprepper.model.event.Event;
import com.amazon.dataprepper.model.processor.AbstractProcessor;
import com.amazon.dataprepper.model.processor.Processor;
import com.amazon.dataprepper.model.record.Record;
import com.fasterxml.jackson.databind.MappingIterator;
import com.fasterxml.jackson.dataformat.csv.CsvMapper;
import com.fasterxml.jackson.dataformat.csv.CsvParser;
import com.fasterxml.jackson.dataformat.csv.CsvSchema;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.List;

/**
 * Processor to parse CSV data in Events.
 *
 */
@DataPrepperPlugin(name="csv", pluginType = Processor.class, pluginConfigurationType = CSVProcessorConfig.class)
public class CSVProcessor extends AbstractProcessor<Record<Event>, Record<Event>> {
    private final CSVProcessorConfig config;

    @DataPrepperPluginConstructor
    public CSVProcessor(final PluginMetrics pluginMetrics, final CSVProcessorConfig config) {
        super(pluginMetrics);
        this.config = config;
    }

    @Override
    public Collection<Record<Event>> doExecute(final Collection<Record<Event>> records) {
        final CsvMapper mapper = createCsvMapper();
        final CsvSchema schema = createCsvSchema();

        for (final Record<Event> record : records) {

            final Event event = record.getData();

            final String message = event.get(config.getSource(), String.class);
            final boolean userDidSpecifyHeaderEventKey = (config.getColumnNamesSourceKey() != null);
            final boolean thisEventHasHeaderSource = userDidSpecifyHeaderEventKey && event.containsKey(config.getColumnNamesSourceKey());

            try {
                final MappingIterator<List<String>> messageIterator = mapper.readerFor(List.class).with(schema).readValues(message);

                // otherwise the message is empty
                if (messageIterator.hasNextValue()) {
                    final List<String> row = messageIterator.nextValue();
                    final List<String> header = parseHeader(event, thisEventHasHeaderSource, mapper, schema);
                    putDataInEvent(event, header, row);
                }

                if (thisEventHasHeaderSource && config.isDeleteHeader()) {
                    event.delete(config.getColumnNamesSourceKey());
                }
            } catch (IOException e) {
                System.out.println(e.toString());
            }
        }
        return records;
    }

    @Override
    public void prepareForShutdown() {

    }

    @Override
    public boolean isReadyForShutdown() {
        return true;
    }

    @Override
    public void shutdown() {

    }

    private CsvMapper createCsvMapper() {
        final CsvMapper mapper = new CsvMapper();
        mapper.enable(CsvParser.Feature.WRAP_AS_ARRAY); // allows mapper to read with empty schema
        return mapper;
    }

    private CsvSchema createCsvSchema() {
        final char delimiterAsChar = config.getDelimiter().charAt(0); // safe due to config input validations
        final char quoteCharAsChar = config.getQuoteCharacter().charAt(0); // safe due to config input validations
        final CsvSchema schema = CsvSchema.emptySchema().withColumnSeparator(delimiterAsChar).withQuoteChar(quoteCharAsChar);
        return schema;
    }

    private List<String> parseHeader(Event event, final boolean thisEventHasHeaderSource, final CsvMapper mapper,
                                     final CsvSchema schema) {
        if (thisEventHasHeaderSource) {
            try {
                final String headerUnprocessed = event.get(config.getColumnNamesSourceKey(), String.class);
                final MappingIterator<List<String>> headerIterator = mapper.readerFor(List.class).with(schema)
                        .readValues(headerUnprocessed);
                // if header is empty, behaves correctly since columns are autogenerated.
                final List<String> headerFromEventSource = headerIterator.nextValue();
                return headerFromEventSource;
            }
            catch (IOException e) {
                final List<String> emptyHeader = new ArrayList<String>();
                return emptyHeader;
            }
        }
        else if (config.getColumnNames() != null) {
            return config.getColumnNames();
        }
        else {
            final List<String> emptyHeader = new ArrayList<String>();
            return emptyHeader;
        }
    }

    private void putDataInEvent(Event event, final List<String> header, final List<String> data) {
        final int dataSize = data.size();
        final int headerSize = header.size();
        if (dataSize <= headerSize) {
            for (int i = 0; i < dataSize; i++) {
                event.put(header.get(i),data.get(i));
            }
        } else {
            int i = 0;
            for (; i < headerSize; i++) {
                event.put(header.get(i),data.get(i));
            }
            for (int j = i; j < dataSize; j++) {
                event.put(generateColumn(j),data.get(j));
            }
        }
    }

    private String generateColumn(int colNumber) {
        final int displayColNumber = colNumber + 1; // just like logstash we 1-index columns
        return "column" + displayColNumber;
    }
}
